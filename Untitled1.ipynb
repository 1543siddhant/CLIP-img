{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "277d887c-2761-4a7c-b40c-5dca9d0a3138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai==0.28.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai==0.28.0) (2.32.2)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from openai==0.28.0) (4.66.4)\n",
      "Requirement already satisfied: aiohttp in c:\\programdata\\anaconda3\\lib\\site-packages (from openai==0.28.0) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28.0) (2024.6.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28.0) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28.0) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28.0) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28.0) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28.0) (1.9.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->openai==0.28.0) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai==0.28.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "741d4acd-8576-45bd-a3ae-5543e6c34f50",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid imaginary literal (1866863376.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    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\u001b[0m\n\u001b[1;37m                                                                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid imaginary literal\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a41678-8143-44c1-ac06-e05690fbe8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')  # Use 'yolov8n.pt' for speed; try 'yolov8m.pt' or 'yolov8l.pt' for higher accuracy\n",
    "\n",
    "# Open the video file\n",
    "video_path = 'mananddog.mp4'  # Change to your video path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Calculate video frame rate and total frames\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# To store descriptions\n",
    "descriptions = []\n",
    "\n",
    "# Process the video, analyzing every 15th frame\n",
    "for frame_num in range(0, total_frames, 15):\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(f\"Error: Could not read frame {frame_num}.\")\n",
    "        break\n",
    "\n",
    "    # Run YOLO object detection\n",
    "    results = model(frame)\n",
    "\n",
    "    # Analyze the detected objects\n",
    "    detected_objects = []\n",
    "    for result in results[0].boxes:\n",
    "        label = model.names[int(result.cls)]\n",
    "        confidence = result.conf.item()  # Convert tensor to float value\n",
    "\n",
    "        # Consider detections with a confidence greater than 0.5\n",
    "        if confidence > 0.5:\n",
    "            detected_objects.append((label, confidence, result.xyxy[0]))  # Store label, confidence, and coordinates\n",
    "\n",
    "            # Draw bounding box around detected object\n",
    "            x1, y1, x2, y2 = map(int, result.xyxy[0])  # Bounding box coordinates\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green bounding box\n",
    "            cv2.putText(frame, f\"{label} ({confidence:.2f})\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    # Generate description based on detected objects\n",
    "    if detected_objects:\n",
    "        # Create a simple description\n",
    "        description = \"In this video, \" + \", \".join([f\"a {label}\" for label, _, _ in detected_objects]) + \" are present.\"\n",
    "        # Add additional details based on positions or actions\n",
    "        if len(detected_objects) > 1:\n",
    "            description += f\" For instance, the {detected_objects[0][0]} is moving with respect to the {detected_objects[1][0]}.\"\n",
    "        descriptions.append(description)\n",
    "\n",
    "    # Optionally, display the frame with detections\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break  # Exit if 'q' is pressed\n",
    "\n",
    "# Release the video capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Generate a summary description of the video\n",
    "if descriptions:\n",
    "    print(\"\\nVideo Descriptions:\")\n",
    "    for desc in descriptions:\n",
    "        print(desc)\n",
    "else:\n",
    "    print(\"No descriptions generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25689374-d917-4c71-8744-7106b80ac15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import openai\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = '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'  # Replace with your actual API key\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')  # Ensure this file is in the correct path\n",
    "\n",
    "# Open the video file\n",
    "video_path = 'mananddog.mp4'  # Change to your video path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Process the video frame by frame\n",
    "descriptions = []\n",
    "frame_skip = 15  # Process every 15th frame for efficiency\n",
    "\n",
    "for frame_num in range(0, int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), frame_skip):\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(f\"Error: Could not read frame {frame_num}.\")\n",
    "        break\n",
    "\n",
    "    # Run YOLO object detection\n",
    "    results = model(frame)\n",
    "\n",
    "    # Collect detected objects\n",
    "    detected_objects = []\n",
    "    for result in results[0].boxes:\n",
    "        label = model.names[int(result.cls)]\n",
    "        confidence = result.conf.item()  # Convert tensor to float value\n",
    "\n",
    "        # Consider detections with a confidence greater than 0.5\n",
    "        if confidence > 0.5:\n",
    "            detected_objects.append(label)  # Store the detected object\n",
    "\n",
    "    # Generate a description using the OpenAI API\n",
    "    if detected_objects:\n",
    "        prompt = f\"Describe the scene with the following objects: {', '.join(detected_objects)}.\"\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4\",  # You can change to \"gpt-3.5-turbo\" if needed\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            \n",
    "            # Extract the generated description\n",
    "            description = response['choices'][0]['message']['content']\n",
    "            descriptions.append(description)\n",
    "            print(f\"Frame {frame_num}: {description}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating description: {e}\")\n",
    "\n",
    "    # Optionally, display the frame with detections\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break  # Exit if 'q' is pressed\n",
    "\n",
    "# Release the video capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Print all descriptions at the end\n",
    "print(\"\\nVideo Descriptions:\")\n",
    "for desc in descriptions:\n",
    "    print(desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "590c0cad-b392-488e-8576-154a837b1bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I help you today? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyDTsGJp1X1NXK6G_tUawD0Ejr5YAKs2zJs\")\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(\"hello\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dcc8d38-f21d-4fba-8940-e0cebab00ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 3 persons, 1 car, 1 dog, 252.3ms\n",
      "Speed: 15.7ms preprocess, 252.3ms inference, 17.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Frame 0: The afternoon sun beat down on the asphalt, casting long shadows from the lone car parked at the curb. A scruffy terrier, its tongue lolling happily, sat beside the open door, patiently waiting for its owner. \n",
      "\n",
      "A young woman, her hair pulled back in a messy bun, emerged from the car, a grocery bag slung over her shoulder. She knelt down to greet the dog, her face breaking into a smile as she scratched behind its ears. \n",
      "\n",
      "A man, his face lined with age and worry, approached them slowly. He held a tattered newspaper in his hand, and his eyes, though clouded with sadness, held a flicker of hope. He stopped a few feet away, glancing nervously between the woman and the dog.\n",
      "\n",
      "The woman stood up, her smile fading slightly.  \"I'm so sorry,\" she said softly. \"But this dog isn't for sale.\" \n",
      "\n",
      "The man's shoulders slumped, and he shuffled away, the newspaper fluttering in his hand like a forgotten flag. The woman watched him go, a knot of sympathy tightening in her chest.  She then turned back to her dog, and they continued their walk down the sun-drenched street. \n",
      "\n",
      "\n",
      "0: 640x384 2 persons, 1 car, 1 cat, 165.1ms\n",
      "Speed: 10.9ms preprocess, 165.1ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Frame 15: The old, faded blue car sat parked beneath a sprawling oak tree, its engine still warm from a recent journey. A ginger cat, sleek and curious, sauntered across the hood, its tail twitching playfully. Two figures stood by the open trunk, their faces illuminated by the warm glow of the setting sun. A young woman, her hair pulled back in a ponytail, rummaged through the contents, while an older man, his face lined with the stories of time, watched her with a smile. The air was thick with the scent of pine and autumn leaves, and the silence was broken only by the chirping of crickets and the rustle of leaves. \n",
      "\n",
      "\n",
      "0: 640x384 2 persons, 1 car, 1 dog, 150.6ms\n",
      "Speed: 6.0ms preprocess, 150.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Frame 30: The late afternoon sun cast long shadows across the empty parking lot. A lone, red sports car sat gleaming in the center, its chrome gleaming like a jewel.  Beside it, a scruffy terrier, barely bigger than a shoebox,  paced nervously, its tail thumping a frantic rhythm against the pavement.  The dogâ€™s brown eyes darted back and forth, waiting for its owner, who was nowhere in sight. \n",
      "\n",
      "A young woman, her hair pulled back in a ponytail, hurried towards the car, a bag of groceries dangling from one hand.  She scanned the parking lot, her brow furrowed in concern.  She spotted the dog, relief washing over her face.  \"Buddy!\" she called out, her voice laced with a mix of exasperation and affection. The dog, his ears perked up, barked happily and bounded towards her, eager to be reunited. \n",
      "\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 165.6ms\n",
      "Speed: 8.0ms preprocess, 165.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Frame 45: Please give me more context! To create a scene, I need more information about:\n",
      "\n",
      "* **The person:**  Are they young or old? What are they wearing? What are they doing? \n",
      "* **The dog:** What breed is it? What size is it? What color is it? What is it doing?\n",
      "* **The setting:** Where are they? Is it indoors or outdoors? Is it sunny or rainy? \n",
      "\n",
      "For example, tell me: \n",
      "\n",
      "* \"A young girl is playing fetch with her golden retriever in a park.\"\n",
      "* \"An elderly man walks his scruffy terrier down a quiet street.\" \n",
      "* \"A dog sits patiently by its owner's side as they wait for a bus.\"\n",
      "\n",
      "The more details you give me, the better I can paint a picture for you! \n",
      "\n",
      "\n",
      "0: 640x384 2 persons, 3 cars, 1 dog, 204.8ms\n",
      "Speed: 6.0ms preprocess, 204.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Frame 60: The setting sun cast long shadows across the deserted street. A beat-up, rusty red car, its paint chipped and faded, sat parked at the curb. Leaning against the car, with a contented sigh, was a young woman, her hair the color of spun gold catching the last rays of sunlight. At her feet, a scruffy terrier, its tail thumping a happy rhythm against the pavement, watched the world go by with unwavering attention. Across the street, another car, sleek and black, pulled to a stop with a quiet hum of the engine.  The woman's eyes lit up as the driver's door opened and a man emerged, his face etched with a smile that mirrored her own. \n",
      "\n",
      "\n",
      "0: 640x384 2 persons, 3 cars, 1 dog, 177.5ms\n",
      "Speed: 5.0ms preprocess, 177.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Frame 75: The morning sun, a golden orb just peeking over the horizon, painted the street in hues of orange and pink.  A lone car, its silver paint reflecting the dawn's light, sat idling at the curb. A small, scruffy dog, a brown and white terrier mix, trotted excitedly along the sidewalk, tail wagging furiously as it sniffed at every lamppost and hydrant.  Across the street, a second car, a bright red sports model, roared to life and sped down the road, leaving a trail of exhaust in its wake.  A young woman, dressed in a bright yellow sundress, stepped out of a third car, a sleek black sedan, and stretched her arms towards the sky.  She smiled, a hint of mischief in her eyes, as she looked towards the dog, who was now happily chasing its own tail. A final car, a faded blue pickup truck, rumbled to life, and the man behind the wheel, his face tired but determined, pulled out into the street, ready to face another busy day. The city, slowly awakening, hummed with the sounds of life, the symphony of engines, barks, and laughter. \n",
      "\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 dog, 140.5ms\n",
      "Speed: 5.9ms preprocess, 140.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Frame 90: Please provide me with some more information!  To paint a picture with the objects you provided, I need more details. For example:\n",
      "\n",
      "* **What kind of car?**  A sleek sports car, a beat-up truck, a family minivan?\n",
      "* **What kind of dog?** A playful puppy, a dignified golden retriever, a grumpy bulldog?\n",
      "* **What is the person doing?**  Walking, running, sitting, talking on their phone?\n",
      "* **What is the relationship between the person and the dog?** Owner, stranger, friend?\n",
      "* **Where are the cars?**  On a busy street, in a quiet driveway, parked in a lot?\n",
      "* **What is the overall mood of the scene?**  Exciting, tense, peaceful, chaotic?\n",
      "\n",
      "Once you tell me more, I can help you create a vivid scene! \n",
      "\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 dog, 176.3ms\n",
      "Speed: 7.0ms preprocess, 176.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Frame 105: The afternoon sun beat down on the asphalt, casting long shadows from the parked cars. A little terrier, tail wagging furiously, darted between the wheels of a red sedan, a playful grin on its face.  Across the street, a woman in a sundress leaned against a blue hatchback, her phone held to her ear, her brow furrowed in concentration. The dog, oblivious to the woman's conversation, continued his happy dance, a mischievous sparkle in his eyes. \n",
      "\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 dog, 126.7ms\n",
      "Speed: 6.0ms preprocess, 126.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Frame 120: The sun beat down on the dusty road, shimmering heat waves dancing in the air. A small, scruffy terrier trotted alongside a weathered pickup truck, its tongue lolling out in the heat. The truck's driver, a man with a sun-baked face and eyes squinting against the glare, leaned out the window, chuckling as the dog chased a tumbleweed rolling across the path. The car, a rusty old sedan, chugged along behind them, its driver seemingly in no hurry to overtake the truck. \n",
      "\n",
      "The scene was a snapshot of the slow, languid pace of life in the countryside, where time moved at a different rhythm.  The dog, the man, and the car were all united by a shared journey, a journey through a sun-drenched world of dusty roads and endless horizons. \n",
      "\n",
      "\n",
      "0: 640x384 1 person, 1 car, 1 dog, 125.5ms\n",
      "Speed: 5.0ms preprocess, 125.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Frame 135: The afternoon sun cast long shadows across the cracked asphalt of the deserted street. A young woman, her face etched with worry, leaned against a faded red car, its dented bumper a testament to years of hard living. Beside her, a scruffy terrier with fur the color of burnt toast whimpered softly, its tail tucked between its legs. The dog's eyes, usually bright and playful, were now filled with a deep sadness that mirrored the woman's own. She gently stroked its head, her touch hesitant, as if afraid to break the fragile calm that hung between them. The silence, punctuated only by the distant hum of traffic, spoke volumes of their shared plight. \n",
      "\n",
      "\n",
      "0: 640x384 5 persons, 1 car, 1 cat, 1 dog, 156.1ms\n",
      "Speed: 6.2ms preprocess, 156.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Frame 150: Please give me more information! I need some context to describe the scene. For example, tell me:\n",
      "\n",
      "* **Where are they?** Are they in a city, on a highway, in a parking lot? \n",
      "* **What is the person doing?** Are they driving, walking, getting into the car? \n",
      "* **What is the car like?** Is it old or new, fancy or basic?\n",
      "* **What is the weather like?** Is it sunny, rainy, snowy?\n",
      "\n",
      "Once I have this information, I can paint a vivid picture for you! \n",
      "\n",
      "\n",
      "0: 640x384 1 person, 1 cat, 1 dog, 137.2ms\n",
      "Speed: 5.5ms preprocess, 137.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Frame 165: Please provide me with more information!  To describe a scene with a person, I need more context.  For example, tell me:\n",
      "\n",
      "* **Where is the person?** Are they in a bustling city street, a quiet forest clearing, or a cozy living room? \n",
      "* **What is the person doing?** Are they reading a book, having a conversation, or staring out the window?\n",
      "* **What is the person's mood?** Are they happy, sad, angry, or contemplative? \n",
      "* **What kind of person are they?** Are they young or old, tall or short, dressed formally or casually?\n",
      "\n",
      "Once I have this information, I can create a detailed and evocative description of the scene. \n",
      "\n",
      "\n",
      "0: 640x384 2 persons, 1 dog, 138.2ms\n",
      "Speed: 8.0ms preprocess, 138.2ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Frame 180: Please provide me with more information! To create a scene with a dog and two people, I need some context. For example:\n",
      "\n",
      "* **Where are they?**  Are they in a park, a house, a forest?\n",
      "* **What are the people doing?** Are they playing fetch, having a picnic, or arguing?\n",
      "* **What kind of dog is it?** Is it a playful puppy, a grumpy old dog, or a majestic wolfhound? \n",
      "\n",
      "Tell me more, and I can help you paint a picture! \n",
      "\n",
      "\n",
      "0: 640x384 1 person, 1 dog, 142.1ms\n",
      "Speed: 5.1ms preprocess, 142.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Frame 195: Please provide me with more context! I need more information to paint a scene.  For example, tell me:\n",
      "\n",
      "* **Where are they?**  In a park, on a beach, in a house?\n",
      "* **What are they doing?**  Playing fetch, cuddling, walking?\n",
      "* **What is the mood?**  Happy, sad, anxious, excited? \n",
      "* **What are their personalities like?**  Is the dog playful and energetic, or calm and gentle? Is the person loving and patient, or aloof and distant?\n",
      "\n",
      "Once I have this information, I can create a vivid and descriptive scene for you. ðŸ˜Š \n",
      "\n",
      "\n",
      "0: 640x384 1 person, 1 dog, 148.1ms\n",
      "Speed: 7.3ms preprocess, 148.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Frame 210: Please provide me with more context! I need more information to paint a picture for you. For example, tell me:\n",
      "\n",
      "* **Where are they?** (park, beach, living room, etc.)\n",
      "* **What are they doing?** (playing fetch, cuddling, walking, etc.)\n",
      "* **What is the atmosphere?** (happy, sad, tense, peaceful, etc.)\n",
      "* **What are their personalities like?** (energetic, calm, playful, etc.)\n",
      "\n",
      "The more details you give me, the more vivid and engaging the scene will be! ðŸ˜Š \n",
      "\n",
      "\n",
      "0: 640x384 1 person, 1 dog, 155.9ms\n",
      "Speed: 5.1ms preprocess, 155.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Error generating description: 429 Resource has been exhausted (e.g. check quota).\n",
      "\n",
      "Video Descriptions:\n",
      "The afternoon sun beat down on the asphalt, casting long shadows from the lone car parked at the curb. A scruffy terrier, its tongue lolling happily, sat beside the open door, patiently waiting for its owner. \n",
      "\n",
      "A young woman, her hair pulled back in a messy bun, emerged from the car, a grocery bag slung over her shoulder. She knelt down to greet the dog, her face breaking into a smile as she scratched behind its ears. \n",
      "\n",
      "A man, his face lined with age and worry, approached them slowly. He held a tattered newspaper in his hand, and his eyes, though clouded with sadness, held a flicker of hope. He stopped a few feet away, glancing nervously between the woman and the dog.\n",
      "\n",
      "The woman stood up, her smile fading slightly.  \"I'm so sorry,\" she said softly. \"But this dog isn't for sale.\" \n",
      "\n",
      "The man's shoulders slumped, and he shuffled away, the newspaper fluttering in his hand like a forgotten flag. The woman watched him go, a knot of sympathy tightening in her chest.  She then turned back to her dog, and they continued their walk down the sun-drenched street. \n",
      "\n",
      "The old, faded blue car sat parked beneath a sprawling oak tree, its engine still warm from a recent journey. A ginger cat, sleek and curious, sauntered across the hood, its tail twitching playfully. Two figures stood by the open trunk, their faces illuminated by the warm glow of the setting sun. A young woman, her hair pulled back in a ponytail, rummaged through the contents, while an older man, his face lined with the stories of time, watched her with a smile. The air was thick with the scent of pine and autumn leaves, and the silence was broken only by the chirping of crickets and the rustle of leaves. \n",
      "\n",
      "The late afternoon sun cast long shadows across the empty parking lot. A lone, red sports car sat gleaming in the center, its chrome gleaming like a jewel.  Beside it, a scruffy terrier, barely bigger than a shoebox,  paced nervously, its tail thumping a frantic rhythm against the pavement.  The dogâ€™s brown eyes darted back and forth, waiting for its owner, who was nowhere in sight. \n",
      "\n",
      "A young woman, her hair pulled back in a ponytail, hurried towards the car, a bag of groceries dangling from one hand.  She scanned the parking lot, her brow furrowed in concern.  She spotted the dog, relief washing over her face.  \"Buddy!\" she called out, her voice laced with a mix of exasperation and affection. The dog, his ears perked up, barked happily and bounded towards her, eager to be reunited. \n",
      "\n",
      "Please give me more context! To create a scene, I need more information about:\n",
      "\n",
      "* **The person:**  Are they young or old? What are they wearing? What are they doing? \n",
      "* **The dog:** What breed is it? What size is it? What color is it? What is it doing?\n",
      "* **The setting:** Where are they? Is it indoors or outdoors? Is it sunny or rainy? \n",
      "\n",
      "For example, tell me: \n",
      "\n",
      "* \"A young girl is playing fetch with her golden retriever in a park.\"\n",
      "* \"An elderly man walks his scruffy terrier down a quiet street.\" \n",
      "* \"A dog sits patiently by its owner's side as they wait for a bus.\"\n",
      "\n",
      "The more details you give me, the better I can paint a picture for you! \n",
      "\n",
      "The setting sun cast long shadows across the deserted street. A beat-up, rusty red car, its paint chipped and faded, sat parked at the curb. Leaning against the car, with a contented sigh, was a young woman, her hair the color of spun gold catching the last rays of sunlight. At her feet, a scruffy terrier, its tail thumping a happy rhythm against the pavement, watched the world go by with unwavering attention. Across the street, another car, sleek and black, pulled to a stop with a quiet hum of the engine.  The woman's eyes lit up as the driver's door opened and a man emerged, his face etched with a smile that mirrored her own. \n",
      "\n",
      "The morning sun, a golden orb just peeking over the horizon, painted the street in hues of orange and pink.  A lone car, its silver paint reflecting the dawn's light, sat idling at the curb. A small, scruffy dog, a brown and white terrier mix, trotted excitedly along the sidewalk, tail wagging furiously as it sniffed at every lamppost and hydrant.  Across the street, a second car, a bright red sports model, roared to life and sped down the road, leaving a trail of exhaust in its wake.  A young woman, dressed in a bright yellow sundress, stepped out of a third car, a sleek black sedan, and stretched her arms towards the sky.  She smiled, a hint of mischief in her eyes, as she looked towards the dog, who was now happily chasing its own tail. A final car, a faded blue pickup truck, rumbled to life, and the man behind the wheel, his face tired but determined, pulled out into the street, ready to face another busy day. The city, slowly awakening, hummed with the sounds of life, the symphony of engines, barks, and laughter. \n",
      "\n",
      "Please provide me with some more information!  To paint a picture with the objects you provided, I need more details. For example:\n",
      "\n",
      "* **What kind of car?**  A sleek sports car, a beat-up truck, a family minivan?\n",
      "* **What kind of dog?** A playful puppy, a dignified golden retriever, a grumpy bulldog?\n",
      "* **What is the person doing?**  Walking, running, sitting, talking on their phone?\n",
      "* **What is the relationship between the person and the dog?** Owner, stranger, friend?\n",
      "* **Where are the cars?**  On a busy street, in a quiet driveway, parked in a lot?\n",
      "* **What is the overall mood of the scene?**  Exciting, tense, peaceful, chaotic?\n",
      "\n",
      "Once you tell me more, I can help you create a vivid scene! \n",
      "\n",
      "The afternoon sun beat down on the asphalt, casting long shadows from the parked cars. A little terrier, tail wagging furiously, darted between the wheels of a red sedan, a playful grin on its face.  Across the street, a woman in a sundress leaned against a blue hatchback, her phone held to her ear, her brow furrowed in concentration. The dog, oblivious to the woman's conversation, continued his happy dance, a mischievous sparkle in his eyes. \n",
      "\n",
      "The sun beat down on the dusty road, shimmering heat waves dancing in the air. A small, scruffy terrier trotted alongside a weathered pickup truck, its tongue lolling out in the heat. The truck's driver, a man with a sun-baked face and eyes squinting against the glare, leaned out the window, chuckling as the dog chased a tumbleweed rolling across the path. The car, a rusty old sedan, chugged along behind them, its driver seemingly in no hurry to overtake the truck. \n",
      "\n",
      "The scene was a snapshot of the slow, languid pace of life in the countryside, where time moved at a different rhythm.  The dog, the man, and the car were all united by a shared journey, a journey through a sun-drenched world of dusty roads and endless horizons. \n",
      "\n",
      "The afternoon sun cast long shadows across the cracked asphalt of the deserted street. A young woman, her face etched with worry, leaned against a faded red car, its dented bumper a testament to years of hard living. Beside her, a scruffy terrier with fur the color of burnt toast whimpered softly, its tail tucked between its legs. The dog's eyes, usually bright and playful, were now filled with a deep sadness that mirrored the woman's own. She gently stroked its head, her touch hesitant, as if afraid to break the fragile calm that hung between them. The silence, punctuated only by the distant hum of traffic, spoke volumes of their shared plight. \n",
      "\n",
      "Please give me more information! I need some context to describe the scene. For example, tell me:\n",
      "\n",
      "* **Where are they?** Are they in a city, on a highway, in a parking lot? \n",
      "* **What is the person doing?** Are they driving, walking, getting into the car? \n",
      "* **What is the car like?** Is it old or new, fancy or basic?\n",
      "* **What is the weather like?** Is it sunny, rainy, snowy?\n",
      "\n",
      "Once I have this information, I can paint a vivid picture for you! \n",
      "\n",
      "Please provide me with more information!  To describe a scene with a person, I need more context.  For example, tell me:\n",
      "\n",
      "* **Where is the person?** Are they in a bustling city street, a quiet forest clearing, or a cozy living room? \n",
      "* **What is the person doing?** Are they reading a book, having a conversation, or staring out the window?\n",
      "* **What is the person's mood?** Are they happy, sad, angry, or contemplative? \n",
      "* **What kind of person are they?** Are they young or old, tall or short, dressed formally or casually?\n",
      "\n",
      "Once I have this information, I can create a detailed and evocative description of the scene. \n",
      "\n",
      "Please provide me with more information! To create a scene with a dog and two people, I need some context. For example:\n",
      "\n",
      "* **Where are they?**  Are they in a park, a house, a forest?\n",
      "* **What are the people doing?** Are they playing fetch, having a picnic, or arguing?\n",
      "* **What kind of dog is it?** Is it a playful puppy, a grumpy old dog, or a majestic wolfhound? \n",
      "\n",
      "Tell me more, and I can help you paint a picture! \n",
      "\n",
      "Please provide me with more context! I need more information to paint a scene.  For example, tell me:\n",
      "\n",
      "* **Where are they?**  In a park, on a beach, in a house?\n",
      "* **What are they doing?**  Playing fetch, cuddling, walking?\n",
      "* **What is the mood?**  Happy, sad, anxious, excited? \n",
      "* **What are their personalities like?**  Is the dog playful and energetic, or calm and gentle? Is the person loving and patient, or aloof and distant?\n",
      "\n",
      "Once I have this information, I can create a vivid and descriptive scene for you. ðŸ˜Š \n",
      "\n",
      "Please provide me with more context! I need more information to paint a picture for you. For example, tell me:\n",
      "\n",
      "* **Where are they?** (park, beach, living room, etc.)\n",
      "* **What are they doing?** (playing fetch, cuddling, walking, etc.)\n",
      "* **What is the atmosphere?** (happy, sad, tense, peaceful, etc.)\n",
      "* **What are their personalities like?** (energetic, calm, playful, etc.)\n",
      "\n",
      "The more details you give me, the more vivid and engaging the scene will be! ðŸ˜Š \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import google.generativeai as genai\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Configure Google Gemini API\n",
    "genai.configure(api_key=\"AIzaSyDTsGJp1X1NXK6G_tUawD0Ejr5YAKs2zJs\")  # Replace with your actual API key\n",
    "gemini_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')  # Ensure this file is in the correct path\n",
    "\n",
    "# Open the video file\n",
    "video_path = 'mananddog.mp4'  # Change to your video path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Process the video frame by frame\n",
    "descriptions = []\n",
    "frame_skip = 15  # Process every 15th frame for efficiency\n",
    "\n",
    "for frame_num in range(0, int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), frame_skip):\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(f\"Error: Could not read frame {frame_num}.\")\n",
    "        break\n",
    "\n",
    "    # Run YOLO object detection\n",
    "    results = model(frame)\n",
    "\n",
    "    # Collect detected objects\n",
    "    detected_objects = []\n",
    "    for result in results[0].boxes:\n",
    "        label = model.names[int(result.cls)]\n",
    "        confidence = result.conf.item()  # Convert tensor to float value\n",
    "\n",
    "        # Consider detections with a confidence greater than 0.5\n",
    "        if confidence > 0.5:\n",
    "            detected_objects.append(label)  # Store the detected object\n",
    "\n",
    "    # Generate a description using the Gemini API\n",
    "    if detected_objects:\n",
    "        prompt = f\"Describe the scene with the following objects: {', '.join(detected_objects)}.\"\n",
    "        try:\n",
    "            response = gemini_model.generate_content(prompt)\n",
    "            description = response.text\n",
    "            descriptions.append(description)\n",
    "            print(f\"Frame {frame_num}: {description}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating description: {e}\")\n",
    "\n",
    "    # Optionally, display the frame with detections\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break  # Exit if 'q' is pressed\n",
    "\n",
    "# Release the video capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Print all descriptions at the end\n",
    "print(\"\\nVideo Descriptions:\")\n",
    "for desc in descriptions:\n",
    "    print(desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adc93ab5-140f-4e31-bc97-70c0560b777c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Prompt:  can you describe the person who is standing infront of the barn. can describe the person \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Video Description:\n",
      "The person standing in front of the barn is wearing a white shirt with a dark blue stripe, dark pants, and a dark blue hat. They are holding a notebook in their right hand. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Configure Google Gemini API\n",
    "genai.configure(api_key=\"AIzaSyDTsGJp1X1NXK6G_tUawD0Ejr5YAKs2zJs\")  # Replace with your actual API key\n",
    "gemini_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# Open the video file\n",
    "video_path = 'raid.mp4'  # Change to your video path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get video details\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "duration = frame_count / fps\n",
    "\n",
    "# Collect information about the video (e.g., resolution, duration)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "resolution = f\"{width}x{height}\"\n",
    "\n",
    "# Close the video\n",
    "cap.release()\n",
    "\n",
    "# Generate a summary description for the entire video using Gemini\n",
    "#prompt = f\"Provide a brief description of the events taking place in the video. can you also describe the surrounding.\"\n",
    "x = input(\"Prompt: \")\n",
    "video = genai.upload_file(video_path)\n",
    "\n",
    "try:\n",
    "    response = gemini_model.generate_content([video,x])\n",
    "    video_description = response.text\n",
    "    print(\"\\nVideo Description:\")\n",
    "    print(video_description)\n",
    "except Exception as e:\n",
    "    print(f\"Error generating video description: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9146ea-6d85-4c76-baf3-f951bdb2f7f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
